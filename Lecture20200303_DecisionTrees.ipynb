{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификаторы на основе деревьев принятия решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import subprocess\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import pymorphy2\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример дерева принятия решения\n",
    "\n",
    "<img src=\"IkBzK.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как определяются лучшие разбиения (best splits)?\n",
    "### Меры неопределенности (impurity measures)\n",
    "\n",
    "Пусть $p_k$ - это доля класса $C_k$ в узле дерева $S$.\n",
    "\n",
    "1. Missclassification error  \n",
    "$$I(S) = 1 - \\max\\limits_k p_k $$\n",
    "2. Gini index \n",
    "$$I(S) = 1 - \\sum\\limits_k (p_k)^2 = \\sum\\limits_{k'\\neq k} p_{k'} p_k$$\n",
    "3. Entropy \n",
    "$$I(S) = -\\sum\\limits_k p_k \\log(p_k)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы построения деревьев\n",
    " \n",
    "** ID 3 **\n",
    "* Только категориальные признаки\n",
    "* Количество потомков = количеству значений признака\n",
    "* Строится до максимальной глубины\n",
    "\n",
    "** С 4.5 **\n",
    "* Поддержка вещественных признаков\n",
    "* Категриальные как в ID3\n",
    "* При пропуске значения переход по всем потомкам\n",
    "* Удаляет избыточные ветвления\n",
    "\n",
    "** СART **\n",
    "* Специальная процедура усещения дерева после построения (post prunning)\n",
    "\n",
    "### Преимущества и недостатки\n",
    "\n",
    "** Преимущества **\n",
    "* Простота построения\n",
    "* Интерпретируемость (при небольшой глубине)\n",
    "* Требуются минимальная предобработка признаков\n",
    "* Встроенный отбор признаков\n",
    "\n",
    "** Недостатки **\n",
    "* Границы строяется только параллельно или перпендикулярно осям\n",
    "* При изменении набора данных надо полностью перестраивать и результат может получится совершенно иным\n",
    "* Жадность построения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Спасибо Андрею Шестакову за пример и демонстрашку.\n",
    "\n",
    "def demo_dec_tree(depth=1):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    fig.set_figheight(5)\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    C = np.array([[0., -0.7], [1.5, 0.7]])\n",
    "    gauss1 = np.dot(np.random.randn(200, 2) + np.array([4, 2]), C)\n",
    "    gauss2 = np.dot(np.random.randn(300, 2), C)\n",
    "\n",
    "    X = np.vstack([gauss1, gauss2])\n",
    "    y = np.r_[np.ones(200), np.zeros(300)]\n",
    "\n",
    "    ax[1].scatter(X[:,0], X[:, 1], c=y)\n",
    "    ax[1].set_xlabel('$x_1$')\n",
    "    ax[1].set_ylabel('$x_2$')\n",
    "\n",
    "    # Dec Tree Stuff\n",
    "    tree = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=123)\n",
    "    tree.fit(X,y)\n",
    "\n",
    "    x_range = np.linspace(X.min(), X.max(), 100)\n",
    "    xx1, xx2 = np.meshgrid(x_range, x_range)\n",
    "\n",
    "    Y = tree.predict(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "    Y = Y.reshape(xx1.shape)\n",
    "\n",
    "    ax[1].contourf(xx1, xx2, Y, alpha=0.3)\n",
    "    ax[1].scatter(X[:,0], X[:,1],c=y)\n",
    "    \n",
    "#     dot_data = StringIO()  \n",
    "#     tree.export_graphviz(tree, out_file=dot_data,  \n",
    "#                      filled=True, rounded=True,  \n",
    "#                      special_characters=True)  \n",
    "#     graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "#     ax[0].imshow(graph[0].create_png())\n",
    "\n",
    "\n",
    "    with open('tree.dot', 'w') as fout:\n",
    "        export_graphviz(tree, out_file=fout, feature_names=['x1', 'x2'], class_names=['0', '1'])\n",
    "    command = [\"dot\", \"-Tpng\", \"tree.dot\", \"-o\", \"tree.png\"]\n",
    "    subprocess.check_call(command)\n",
    "    ax[0].imshow(plt.imread('tree.png'))\n",
    "    ax[0].axis(\"off\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86c4e7760b3469d988fdabde686633e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    fig = interact(demo_dec_tree, depth=IntSlider(min=1, max=5, value=1))\n",
    "except:\n",
    "    print('Что-то не так. Посмотрите на доску')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем какое-то количество научных статей разной тематики и сформируем из них набор данных. Нашей задачей будет классифицировать статьи по разделам науки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Внимание!!! **\n",
    "Исходные файлы со статьями, из которых проводилась выборка не предоставляются! В связи с этим код ниже работать не будет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_cyberleninka_archi2.txt\n",
      "all_cyberleninka_arts2.txt\n",
      "all_cyberleninka_auto2.txt\n",
      "all_cyberleninka_bio2.txt\n",
      "all_cyberleninka_chemystry2.txt\n",
      "all_cyberleninka_cyber2.txt\n"
     ]
    }
   ],
   "source": [
    "path=\"/home/edward/projects/TEST/getRusCorpora/Python/\"\n",
    "files=[\"all_cyberleninka_archi2.txt\", \"all_cyberleninka_arts2.txt\", \"all_cyberleninka_auto2.txt\", \"all_cyberleninka_bio2.txt\", \"all_cyberleninka_chemystry2.txt\", \"all_cyberleninka_cyber2.txt\"]\n",
    "\n",
    "classes=[]\n",
    "texts=[]\n",
    "\n",
    "for c, name in enumerate(files):\n",
    "    print(name)\n",
    "    with open(path+name) as fil:\n",
    "        txt=fil.read()\n",
    "        arts=txt.split(\"\\n=====\\n\")\n",
    "        texts.extend(arts[1:51])\n",
    "        classes.extend([c for i in range(50)])\n",
    "        \n",
    "txt=\"\"\n",
    "arts=[]\n",
    "\n",
    "with open(\"cyber_dataset.txt\", \"wt\") as fil:\n",
    "    fil.write(\" \".join([str(c) for c in classes])+\"\\n=====\\n\")\n",
    "    for text in texts:\n",
    "        fil.write(text)\n",
    "        fil.write(\"\\n=====\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем файл со сформированным набором данных и прочитаем статьи в память. После этого сформируем частотные словари для статей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticleDictionary(morph, text):\n",
    "    words=[a[0] for a in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "    reswords=[]\n",
    "\n",
    "    for w in words:\n",
    "        wordform=morph.parse(w)[0]\n",
    "        try:\n",
    "            if wordform.tag.POS in ['ADJF', 'NOUN', 'VERB', 'PRTF', 'INFN']:\n",
    "                reswords.append(wordform.normal_form)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    stat=Counter(reswords)\n",
    "    # Берем только слова с частотой больше 1.\n",
    "    stat={a: stat[a] for a in stat.keys() if stat[a]>1}\n",
    "    return stat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph=pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:20<00:00, 14.96it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"cyber_dataset.txt\", \"rt\") as fil:\n",
    "    text=fil.read()\n",
    "articles=text.split(\"\\n=====\\n\")\n",
    "classes=articles[0].split(' ')\n",
    "dicts=[]\n",
    "for art in tqdm(articles[1:-1]):\n",
    "    dicts.append(getArticleDictionary(morph, art))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy', random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words={}\n",
    "for d in dicts:\n",
    "    for word in d.keys():\n",
    "        if word not in all_words.keys():\n",
    "            all_words[word]=len(all_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words=list([list(d.keys()) for d in dicts])\n",
    "words=[np.array([1 if w in d.keys() else 0 for w in all_words.keys()]) for d in dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(words, classes, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=333, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', '3'),\n",
       " ('3', '3'),\n",
       " ('5', '5'),\n",
       " ('5', '5'),\n",
       " ('0', '2'),\n",
       " ('4', '4'),\n",
       " ('3', '1'),\n",
       " ('1', '1'),\n",
       " ('1', '1'),\n",
       " ('4', '4'),\n",
       " ('3', '3'),\n",
       " ('4', '4'),\n",
       " ('1', '1'),\n",
       " ('2', '2'),\n",
       " ('1', '0'),\n",
       " ('5', '2'),\n",
       " ('5', '5'),\n",
       " ('1', '0'),\n",
       " ('1', '1'),\n",
       " ('3', '3'),\n",
       " ('4', '2'),\n",
       " ('1', '1'),\n",
       " ('3', '4'),\n",
       " ('5', '2'),\n",
       " ('3', '3'),\n",
       " ('1', '1'),\n",
       " ('3', '3'),\n",
       " ('5', '5'),\n",
       " ('0', '0'),\n",
       " ('4', '3'),\n",
       " ('1', '0'),\n",
       " ('3', '3'),\n",
       " ('0', '5'),\n",
       " ('5', '2'),\n",
       " ('1', '1'),\n",
       " ('0', '0'),\n",
       " ('5', '5'),\n",
       " ('2', '2'),\n",
       " ('4', '4'),\n",
       " ('3', '3'),\n",
       " ('0', '0'),\n",
       " ('4', '4'),\n",
       " ('0', '2'),\n",
       " ('5', '5'),\n",
       " ('1', '1'),\n",
       " ('0', '0'),\n",
       " ('3', '4'),\n",
       " ('3', '1'),\n",
       " ('1', '1'),\n",
       " ('5', '5'),\n",
       " ('0', '3'),\n",
       " ('1', '0'),\n",
       " ('5', '5'),\n",
       " ('5', '5'),\n",
       " ('0', '0'),\n",
       " ('4', '5'),\n",
       " ('3', '3'),\n",
       " ('3', '3'),\n",
       " ('5', '5'),\n",
       " ('2', '2')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1 for i, j in zip(y_hat, y_test) if i==j])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  4,  0,  0,  0,  0],\n",
       "       [ 0,  9,  0,  2,  0,  0],\n",
       "       [ 2,  0,  3,  0,  1,  3],\n",
       "       [ 1,  0,  0, 10,  1,  0],\n",
       "       [ 0,  0,  0,  2,  5,  0],\n",
       "       [ 1,  0,  0,  0,  1, 10]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat)\n",
    "\n",
    "#max_depth\n",
    "#criterion='entropy',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest=RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat2=forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1 for i, j in zip(y_hat2, y_test) if i==j])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  4,  0,  0,  0,  0],\n",
       "       [ 0, 11,  0,  0,  0,  0],\n",
       "       [ 2,  1,  3,  0,  0,  3],\n",
       "       [ 0,  0,  0, 10,  1,  1],\n",
       "       [ 0,  0,  0,  1,  6,  0],\n",
       "       [ 0,  0,  0,  0,  2, 10]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
